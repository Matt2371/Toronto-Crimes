{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Modeling\n",
    "In this notebook, we explore various models to predict crime type based on various time and location predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_performance(y_true, y_pred, classes, y_score=None):\n",
    "    \"\"\"\n",
    "    Returns a dataframe that summarizes performance metrics (accuracy, f1, precision, recall)\n",
    "    for each class and the overall score (which returns a weighted average of all the scores \n",
    "    based on the number of true instances)\n",
    "\n",
    "    y_true: np.array(n, ); true class labels\n",
    "    y_pred: np.array(n, ); predicted class labels\n",
    "    classes: list of class labels (from label_encoder.classes_ for example)\n",
    "    y_score: currently not used;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add overall to classes to create list of columns\n",
    "    column_list = np.concatenate([classes, ['Overall']])\n",
    "\n",
    "    result = np.empty(shape=(4, len(classes) + 1), dtype=np.dtype(object))\n",
    "    # F1 scores\n",
    "    result[0] = np.concatenate([f1_score(y_true, y_pred, average=None),\n",
    "                               [f1_score(y_true, y_pred, average='micro')]])\n",
    "    # Precision\n",
    "    result[1] = np.concatenate([precision_score(y_true, y_pred, average=None),\n",
    "                               [precision_score(y_true, y_pred, average='micro')]])\n",
    "    # Recall\n",
    "    result[2] = np.concatenate([precision_score(y_true, y_pred, average=None),\n",
    "                               [precision_score(y_true, y_pred, average='micro')]])\n",
    "    # Accuracy\n",
    "    filler_list = [''] * len(classes)\n",
    "    filler_list.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    result[3] = filler_list\n",
    "                               \n",
    "    # Convert result to pandas df\n",
    "    df = pd.DataFrame(result, columns=column_list, index=['f1', 'precision', 'recall', 'accuracy'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data\n",
    "Since the data has many categorical features, we need to encode them in order to use sci-kit learn implementations of the different models. Options that we will explore are:\n",
    "\n",
    "1. One-hot-encoding. Covert each level of the categorical feature into binary indicator variables. The problem with one-hot-encoding is that it can dramatically increase the dimensionality of the data which will increase the computational cost of training and increases the overfitting risk (increases model variance)\n",
    "\n",
    "2. Ordinal encoding. Assign each level of the categorical feature an integer. While this does not increase the dimensionality of the data, it can introduce bias since the model can interpret the variables based on its magnitude while in reality the numerical values were arbitrarily assigned. This can be less of an issue with tree-based methods, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv data\n",
    "df = pd.read_csv('data/clean_data.csv')\n",
    "# Drop un-needed or already processed columns\n",
    "df = df.drop(columns=['OBJECTID', 'OCC_HOUR', 'OCC_DATE', 'dayofweek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get one-hot-encoded data\n",
    "df1 = pd.get_dummies(df[['NEIGHBOURHOOD_158', 'LOCATION_TYPE']])\n",
    "\n",
    "# Combine with original data\n",
    "df_one_hot = pd.concat([df, df1], axis=1)\n",
    "\n",
    "X_one_hot = df_one_hot.drop(columns=['MCI_CATEGORY', 'NEIGHBOURHOOD_158', 'LOCATION_TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get ordinal encoded data\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "df_ordinal = df.copy() # write on top of a copy of df\n",
    "df_ordinal.loc[:, ['NEIGHBOURHOOD_158', 'LOCATION_TYPE']] = ordinal_encoder.fit_transform(df[['NEIGHBOURHOOD_158', 'LOCATION_TYPE']]) # create labels\n",
    "\n",
    "X_ordinal = df_ordinal.drop(columns=['MCI_CATEGORY', 'NEIGHBOURHOOD_158', 'LOCATION_TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Assault', 'Auto Theft', 'Break and Enter', 'Robbery',\n",
       "       'Theft Over'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Process y with one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['MCI_CATEGORY'])\n",
    "\n",
    "# Encoded classes\n",
    "classes = label_encoder.classes_\n",
    "classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Random Forest is capable of handling mixed data types, performs automatic feature selection, is robust to outliers, and discovers non-linear relationships. Since Random Forest averages many different decision trees, it is also not prone to overfitting and has low variance in the bias-variance tradeoff. RF is also useful because it discovers feature importance scores, although this needs to be carefully interpreted if there are colinear variables or if variables are of high cardinality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_one_hot, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Fit model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train1, y_train1)\n",
    "\n",
    "# Get predictions\n",
    "y_pred1 = rf.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assault</th>\n",
       "      <th>Auto Theft</th>\n",
       "      <th>Break and Enter</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Theft Over</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.757149</td>\n",
       "      <td>0.57925</td>\n",
       "      <td>0.551668</td>\n",
       "      <td>0.466324</td>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.655847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.706495</td>\n",
       "      <td>0.598515</td>\n",
       "      <td>0.591509</td>\n",
       "      <td>0.553245</td>\n",
       "      <td>0.165517</td>\n",
       "      <td>0.655847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.706495</td>\n",
       "      <td>0.598515</td>\n",
       "      <td>0.591509</td>\n",
       "      <td>0.553245</td>\n",
       "      <td>0.165517</td>\n",
       "      <td>0.655847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.655847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Assault Auto Theft Break and Enter   Robbery Theft Over   Overall\n",
       "f1         0.757149    0.57925        0.551668  0.466324   0.080172  0.655847\n",
       "precision  0.706495   0.598515        0.591509  0.553245   0.165517  0.655847\n",
       "recall     0.706495   0.598515        0.591509  0.553245   0.165517  0.655847\n",
       "accuracy                                                             0.655847"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "multi_performance(y_true=y_test1, y_pred=y_pred1, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assault            0.534758\n",
       "Break and Enter    0.193989\n",
       "Auto Theft         0.142905\n",
       "Robbery            0.095363\n",
       "Theft Over         0.032985\n",
       "Name: MCI_CATEGORY, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review class frequencies in the data\n",
    "df.MCI_CATEGORY.value_counts() / df.MCI_CATEGORY.value_counts().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
